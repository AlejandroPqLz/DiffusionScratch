{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pokémon Diffusion<a id=\"top\"></a>**\n",
    "\n",
    "> #### ``04-Training-Diffusion-Model.ipynb``\n",
    "\n",
    "<i><small>**Alumno:** Alejandro Pequeño Lizcano<br>Última actualización: 11/03/2024</small></i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "Una vez que hemos establecido todos los pasos para el preprocesamiento de datos y definido la arquitectura del modelo de difusión, avanzamos hacia la etapa de entrenamiento del modelo. En esta fase, hemos desarrollado funciones auxiliares destinadas a visualizar los resultados del modelo a medida que se lleva a cabo el entrenamiento y también para poder visualizar los resultados finales del modelo una vez que se ha completado el entrenamiento.\n",
    "\n",
    "Iniciamos con la función ``sampling()``, la cual despliega muestras conforme el modelo se entrena y nos proporciona una herramienta fundamental para evaluar y visualizar el rendimiento del modelo a medida que evoluciona a lo largo del tiempo y la difusión inversa. En primer lugar, se establece $\\beta$ y los valores correspondientes de $\\alpha$ que desempeñan un papel esencial en la difusión inversa. Posteriormente, se inicializa el ruido, dando inicio al proceso a lo largo de los pasos de difusión. Cada iteración implica la normalización del tiempo, la generación de ruido y la predicción del modelo. La imagen final es obtenida después de aplicar la resta del ruido predicho en un instante de tiempo $t$ a la imagen en ese mismo instante, dando como resultado la imagen en el instante $t-1$. Este proceso se repite hasta que se obtiene la imagen original: $x_{0}$.\n",
    "\n",
    "Dicha función sigue el algoritmo 2 de [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) y se ha modificado para que sea capaz de generar imágenes condicionadas a una etiqueta. Para ello, se ha añadido el parámetro ``label`` al modelo ``build_ddpm_model()``. Esto permite que el modelo de difusión genere imágenes de un tipo de pokemon concreto.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1048/1*UxxYjCEfV99i-drcTZp87w.png\" width=\"40%\" height=\"30%\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 2: Sampling\n",
    "# =====================================================================\n",
    "def sampling(\n",
    "    model: tf.keras.models.Model,\n",
    "    start_noise: np.ndarray,\n",
    "    T: int = T,\n",
    "    scheduler: str = \"linear\",\n",
    "    beta_start: float = beta_start,\n",
    "    beta_end: float = beta_end,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Samples an image from the model.\n",
    "\n",
    "    :param model: The model to sample from.\n",
    "    :param start_noise: The noise to start the sampling from.\n",
    "    :param T: The number of timesteps to sample for.\n",
    "    :param scheduler: The type of schedule to use. Options are \"linear\" or \"cosine\".\n",
    "    :param beta_start: Starting value of beta.\n",
    "    :param beta_end: Ending value of beta.\n",
    "    :return: The sampled image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the beta schedule and corresponding alpha values\n",
    "    beta = beta_scheduler(scheduler, T, beta_start, beta_end)\n",
    "    alpha = 1.0 - beta\n",
    "    alpha_cumprod = np.cumprod(alpha)\n",
    "\n",
    "    # Set the starting noise\n",
    "    x_t = start_noise  # 1: x_T ~ N(0, I)\n",
    "\n",
    "    # Reverse the diffusion process\n",
    "    for t in tqdm(\n",
    "        reversed(range(1, T)), desc=\"Sampling\", total=T - 1, leave=False\n",
    "    ):  # 2: for t = T − 1, . . . , 1 do\n",
    "        # Compute normalized timestep\n",
    "        normalized_t = np.array([t / T]).reshape(1, -1).astype(\"float32\")\n",
    "        # Sample z_t\n",
    "        z = (\n",
    "            np.random.normal(size=x_t.shape)\n",
    "            if t > 1\n",
    "            else np.zeros(x_t.shape).astype(\"float32\")\n",
    "        )  # 3: z ∼ N(0, I) if t > 1, else z = 0\n",
    "        # Calculate x_(t-1)\n",
    "        predicted_noise = model.predict(\n",
    "            [x_t, normalized_t], verbose=0\n",
    "        )  # Predict the noise estimate using the model = eps_theta\n",
    "        x_t = (\n",
    "            x_t - (1 - alpha[t]) / np.sqrt(1 - alpha_cumprod[t]) * predicted_noise\n",
    "        ) / np.sqrt(alpha[t]) + np.sqrt(\n",
    "            beta[t]\n",
    "        ) * z  # 4: x_(t-1) = (x_t - (1 - alpha_t) / sqrt(1 - alpha_cumprod_t) * eps_theta) / sqrt(alpha_t) + sigma_t * z\n",
    "\n",
    "    # Return the final sample\n",
    "    return x_t  # 5: return x_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones auxiliares proporcionadas cumplen roles importantes para la evaluación y visualización del modelo de difusión:\n",
    "\n",
    "- ``generate_em()``: Esta función crea una etiqueta aleatoria para condicionar el modelo de difusión. Genera un vector de ceros de longitud num_classes y asigna el valor 1 en una posición aleatoria dentro del vector.\n",
    "\n",
    "- ``plot_samples()``: visualiza muestras generadas por el modelo de difusión a partir de las funciones mencionadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "# =====================================================================\n",
    "\n",
    "\n",
    "# Generate a random embedding (label) =====================================================================\n",
    "def generate_em(num_classes: int = NUM_CLASSES) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a random embedding (label)\n",
    "    :param num_classes: The number of classes\n",
    "    \"\"\"\n",
    "    em = np.zeros(num_classes)\n",
    "    em[np.random.randint(0, num_classes - 1)] = 1\n",
    "    return em\n",
    "\n",
    "\n",
    "# Plot samples function =====================================================================\n",
    "def plot_samples(\n",
    "    model: tf.keras.models.Model,\n",
    "    num_samples: int = 2,\n",
    "    T: int = T,\n",
    "    scheduler: str = \"linear\",\n",
    "    beta_start: float = beta_start,\n",
    "    beta_end: float = beta_end,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots samples from the model.\n",
    "\n",
    "    :param model: The model to sample from.\n",
    "    :param num_samples: The number of samples to plot.\n",
    "    :param T: The number of timesteps to sample for.\n",
    "    :param scheduler: The type of schedule to use. Options are \"linear\" or \"cosine\".\n",
    "    :return: The sampled image.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        1, num_samples, figsize=(num_samples * 2, 2)\n",
    "    )  # Creating a row of subplots\n",
    "\n",
    "    for i in trange(num_samples, desc=\"Sample plot\", leave=True):\n",
    "        start_noise = np.random.normal(size=(1, IMG_SIZE, IMG_SIZE, 3)).astype(\n",
    "            \"float32\"\n",
    "        )\n",
    "        y_label = generate_em().reshape(\n",
    "            1, 18\n",
    "        )  # reshape to (1,18) to match the model input\n",
    "        sample = sampling(\n",
    "            model, start_noise, y_label, T, scheduler, beta_start, beta_end\n",
    "        )\n",
    "        sample = (sample + 1.0) / 2.0  # Scale to [0, 1]\n",
    "        axs[i].imshow(sample[0])\n",
    "        axs[i].title.set_text(\n",
    "            onehot_to_string(y_label[0])\n",
    "        )  # use the onehot_to_string function described above\n",
    "        axs[i].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Como paso final, se procede a entrenar el modelo de difusión. Para ello, se ha definido la función ``training()`` que engloba todo el proceso de difusión completo, tanto hacia adelante como hacia atrás y los ploteos de las muestras generadas. Para implementar el training hemos usado el **Algoritmo 1** de [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) y se ha modificado para que sea capaz de generar imágenes condicionadas a una etiqueta.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*XbNgIrfo269LT9QKGcg2lw.png\" width=\"40%\" height=\"30%\" />\n",
    "</div>\n",
    "\n",
    "Tambiñen se han añadido unas funcionalidades extra que permiten guardar cada epoch el modelo y sus pesos en un fichero con extensión .h5. Esto se hace para poder cargar el modelo y continuar el entrenamiento desde donde se quedó en caso de que se interrumpa por algún motivo.\n",
    "\n",
    "<span style=\"color: red; font-size: 1.5em;\">&#9888;</span> <i><small>**NOTA:** Por cada epoch se guarda en un fichero con extensión .h5 tanto el modelo como sus pesos. Este proceso se realiza ya que todo el entrenamiento es muy costoso y si se interrumpe por algún motivo, se puede volver a cargar el modelo y continuar el entrenamiento desde donde se quedó.\n",
    "\n",
    "También cabe destacar que para una mayor eficiencia en el entrenamiento, se ha optado por realizar el ``sampling()`` cada 5 epochs.\n",
    "</small></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1: Training\n",
    "# =====================================================================\n",
    "def training(\n",
    "    model: tf.keras.models.Model,\n",
    "    dataset: tf.data.Dataset,\n",
    "    optimizer: tf.keras.optimizers.Optimizer,\n",
    "    loss_fn: tf.keras.losses.Loss,\n",
    "    total_epochs: int = 10,\n",
    "    scheduler: str = \"cosine\",\n",
    "    T: int = 100,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Performs the training loop.\n",
    "\n",
    "    :param model: The model to train.\n",
    "    :param dataset: The training dataset.\n",
    "    :param optimizer: The optimizer to use.\n",
    "    :param loss_fn: The loss function to use.\n",
    "    :param total_epochs: The number of epochs to train for.\n",
    "    :param scheduler: The type of schedule to use. Options are \"linear\" or \"cosine\".\n",
    "    :param T: The number of timesteps to sample for.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Save intermodels by epoch\n",
    "    # =====================================================================\n",
    "\n",
    "    # Create the folder to save the models by epoch\n",
    "    folder_epoch = f\"../../models/inter_models/diffusion_{IMG_SIZE}_{BATCH_SIZE}_{EPOCHS}_{T}_{scheduler}_ddpm\"\n",
    "    if not os.path.exists(folder_epoch):\n",
    "        os.makedirs(folder_epoch)\n",
    "\n",
    "    # Check if there are checkpoints to load\n",
    "    if len(glob.glob(f\"{folder_epoch}/diffusion_{scheduler}_*.h5\")) > 0:\n",
    "\n",
    "        last_checkpoint = sorted(\n",
    "            glob.glob(f\"{folder_epoch}/diffusion_{scheduler}*.h5\"),\n",
    "            key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]),\n",
    "        )[\n",
    "            -1\n",
    "        ]  # Get the last checkpoint\n",
    "        print(f\"Loading checkpoint {last_checkpoint}...\")\n",
    "\n",
    "        # Get the epoch from the checkpoint\n",
    "        prev_epoch = int(\n",
    "            last_checkpoint.split(\"_\")[-1].split(\".\")[0]\n",
    "        )  # Get the epoch from the checkpoint\n",
    "        print(f\"Resuming training from epoch {prev_epoch}...\")\n",
    "\n",
    "        model = tf.keras.models.load_model(\n",
    "            f\"{folder_epoch}/diffusion_{scheduler}_{prev_epoch}.h5\"\n",
    "        )  # Load the model\n",
    "\n",
    "    else:\n",
    "        prev_epoch = 0\n",
    "        print(\"No checkpoints found, starting training from scratch...\")\n",
    "\n",
    "    # Start the training loop\n",
    "    # =====================================================================\n",
    "\n",
    "    # Get scheduler values\n",
    "    beta = beta_scheduler(scheduler, T, beta_start, beta_end)  # Get beta\n",
    "    alpha = 1.0 - beta  # Get alpha\n",
    "    alpha_cumprod = np.cumprod(alpha)  # Get alpha cumulative product\n",
    "\n",
    "    for epoch in trange(\n",
    "        prev_epoch,\n",
    "        total_epochs,\n",
    "        desc=f\"Training\",\n",
    "        total=total_epochs - prev_epoch,\n",
    "        leave=True,\n",
    "    ):  # 1: repeat (iterations through the epochs)\n",
    "        for step, input_data in tqdm(\n",
    "            enumerate(dataset),\n",
    "            desc=f\"Epoch {epoch+1}/{total_epochs}\",\n",
    "            total=len(dataset),\n",
    "            leave=True,\n",
    "        ):  # 1: repeat (iterations through the batches)\n",
    "            # Generate a single timestep for one entire batch\n",
    "            t = np.random.randint(0, T)\n",
    "            normalized_t = np.full(\n",
    "                (input_data.shape[0], 1), t / T, dtype=np.float32\n",
    "            )  # 3: t ~ U(0, T)\n",
    "\n",
    "            # Get the target noise\n",
    "            noised_data = forward_diffusion(input_data, t, scheduler)  # 2: x_0 ~ q(x_0)\n",
    "            target_noise = noised_data - input_data * np.sqrt(\n",
    "                alpha_cumprod[t]\n",
    "            )  # 4: eps_t ~ N(0, I)\n",
    "\n",
    "            # 5: Take a gradient descent step on\n",
    "            with tf.GradientTape() as tape:\n",
    "                predicted_noise = model(\n",
    "                    [noised_data, normalized_t], training=True\n",
    "                )  # eps_theta -> model(x_t, t/T)\n",
    "                loss = loss_fn(\n",
    "                    target_noise, predicted_noise\n",
    "                )  # gradient of the loss (MSE(eps_t, eps_theta))\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        print(f\"EPOCH {epoch+1} LOSS: {loss.numpy():.4f} \\n{'='*69}\")\n",
    "\n",
    "        # Save the model at the end of every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"\\tSaving model in epoch {epoch+1}\")\n",
    "            model.save(f\"{folder_epoch}/diffusion_{scheduler}_{epoch+1}.h5\")\n",
    "\n",
    "        # Sample and plot every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(\"\\tSampling images...\")\n",
    "            plot_samples(model, num_samples=3, scheduler=scheduler, T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# =====================================================================\n",
    "training(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    scheduler=\"cosine\",\n",
    "    num_epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "\n",
    "Finalmente, se guardan los resultados finales del modelo de difusión en un fichero `.h5` para su posterior uso y visualización. TODO: MIRAR OTROS FORMATOS DE GUARDADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model function\n",
    "# =====================================================================\n",
    "def save_model(model: tf.keras.models.Model, model_name: str) -> None:\n",
    "    \"\"\"Saves the model\n",
    "\n",
    "    :param model: The model to save\n",
    "    :param model_name: The name of the model\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the model\n",
    "    model_dir = \"./diffusion_models/models/\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    if not os.path.exists(os.path.join(model_dir, f\"{model_name}.h5\")):\n",
    "        model.save(os.path.join(model_dir, f\"{model_name}.h5\"))\n",
    "        print(f\"Model {model_name}, saved successfully!\")\n",
    "    else:\n",
    "        print(f\"Model {model_name}, already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_name = f\"diffusion_{IMG_SIZE}_{BATCH_SIZE}_{EPOCHS}_{T}_{scheduler}_ddpm\"\n",
    "\n",
    "save_model(model, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
