{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# =====================================================================\n",
    "import os\n",
    "\n",
    "# Configurar el nivel de logging para mostrar solo errores\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import configparser\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Import src code\n",
    "from src.model.build_unet import build_unet\n",
    "from src.utils.utils import PROJECT_DIR, DATA_PATH\n",
    "from src.visualization import visualize\n",
    "from src.model.overfitting_test import *\n",
    "from src.data.create_dataset import dataset_tf\n",
    "from src.data.path_loader import PathLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the GPU\n",
    "# =====================================================================\n",
    "gpus_list = tf.config.list_physical_devices(\"GPU\")\n",
    "gpu = gpus_list[0]\n",
    "tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(\"GPUs Available: \", gpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config file\n",
    "# =====================================================================\n",
    "config = configparser.ConfigParser()\n",
    "config.read(PROJECT_DIR / \"config.ini\")\n",
    "\n",
    "# Hyperparameters\n",
    "config_hp = config[\"hyperparameters\"]\n",
    "\n",
    "IMG_SIZE = 64\n",
    "NUM_CLASSES = int(config_hp[\"num_classes\"])\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "T = int(config_hp[\"T\"])  # number of diffusion steps\n",
    "BETA_START = float(config_hp[\"beta_start\"])\n",
    "BETA_END = float(config_hp[\"beta_end\"])\n",
    "s = float(config_hp[\"s\"])  # scale factor for the variance curve\n",
    "SCHEDULER = config_hp[\"scheduler\"]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  # TODO: ADD TO CONFIG FILE\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv data\n",
    "# =====================================================================\n",
    "path = f\"{DATA_PATH}/processed/pokedex_cleaned.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Show the df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"{DATA_PATH}/processed/pokemon_tf_dataset\"\n",
    "# poke_dataset = tf.data.Dataset.load(path=dataset_path, compression=\"GZIP\")\n",
    "\n",
    "poke_dataset = dataset_tf(\n",
    "    image_paths=PathLoader.get_image_paths(f\"{DATA_PATH}/interim/image_paths.json\"),\n",
    "    df=df,\n",
    "    img_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save=False,\n",
    "    save_path=dataset_path,\n",
    ")\n",
    "\n",
    "# Check the dataset\n",
    "# =====================================================================\n",
    "for img, label in poke_dataset.take(1):\n",
    "    print(\n",
    "        f\"- The shape of the dataset is: {img.shape} => batch_size: {img.shape[0]}, height: {img.shape[1]}, width: {img.shape[2]}, channels: {img.shape[3]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"- The shape of the dataset labels is: {label.shape} => batch_size: {label.shape[0]}, number of labels: {label.shape[1]}\"\n",
    "    )\n",
    "\n",
    "# Visualize the dataset\n",
    "visualize.plot_images_batch(dataset_tf=poke_dataset, n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "# =====================================================================\n",
    "u_net = build_unet(IMG_SIZE, NUM_CLASSES)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model = DiffusionModel(\n",
    "    u_net, IMG_SIZE, NUM_CLASSES, T, BETA_START, BETA_END, s, \"linear\"\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "# =====================================================================\n",
    "model.compile(loss=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(True)  # to debug the model\n",
    "model.fit(poke_dataset, epochs=EPOCHS, callbacks=[DiffusionCallback(model, 20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(True)  # to debug the model\n",
    "model.fit(poke_dataset, epochs=500, callbacks=[DiffusionCallback(model, 20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_samples(6)\n",
    "\n",
    "model.plot_samples(3, \"Fire\")\n",
    "model.plot_samples(3, \"Grass\")\n",
    "model.plot_samples(3, \"Water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_samples(6)\n",
    "model.plot_samples(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Save Model\n",
    "\n",
    "Finalmente, se guardan los resultados finales del modelo de difusión en un fichero `.h5` para su posterior uso y visualización. TODO: MIRAR OTROS FORMATOS DE GUARDADO\n",
    "\n",
    "TODO: INVESTIGAR OTROS FORMATOS DE GUARDADO (HDF5, PICKLE, ETC.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model function\n",
    "# =====================================================================\n",
    "def save_model(model: tf.keras.models.Model, model_name: str) -> None:\n",
    "    \"\"\"Saves the model\n",
    "\n",
    "    :param model: The model to save\n",
    "    :param model_name: The name of the model\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the model\n",
    "    model_dir = \"../../models/\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    if not os.path.exists(os.path.join(model_dir, f\"{model_name}.h5\")):\n",
    "        model.save(os.path.join(model_dir, f\"{model_name}.keras\"))\n",
    "        print(f\"Model {model_name}, saved successfully!\")\n",
    "    else:\n",
    "        print(f\"Model {model_name}, already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "SCHEDULER = \"linear\"\n",
    "EPOCHS = 600\n",
    "model_name = f\"diffusion_{IMG_SIZE}_{BATCH_SIZE}_{EPOCHS}_{T}_{SCHEDULER}_ddpm\"\n",
    "\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "# =====================================================================\n",
    "model_loaded = tf.keras.models.load_model(f\"../../models/{model_name}.keras\")\n",
    "\n",
    "model_load.plot_samples(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BACK TO TOP](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
