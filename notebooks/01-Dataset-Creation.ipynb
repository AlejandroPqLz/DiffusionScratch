{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pokémon Diffusion<a id=\"top\"></a>**\n",
    "\n",
    "> #### ``01-Dataset-Creation.ipynb``\n",
    "\n",
    "<i><small>**Alumno:** Alejandro Pequeño Lizcano<br>Última actualización: 18/03/2024</small></i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook tiene como objetivo el preprocesado de tanto las imágenes de Pokémon como de sus tipos para la posterior creación de un dataset que permita entrenar el modelo de difusión.\n",
    "\n",
    "Para ello, ste notebook se dividirá en las siguientes secciones:\n",
    "\n",
    "- [0. Imports](#-0.-Imports)\n",
    "\n",
    "- [1. Carga de datos](#-1.-Carga-de-datos)\n",
    "\n",
    "- [2. Preprocesamiento y creación del dataset](#-2.-Preprocesamiento-y-creación-del-dataset)\n",
    "\n",
    "    - [2.1. Asignación de tipos a los Pokémon](#-2.1.-Asignación-de-tipos-a-los-Pokemón)\n",
    "    - [2.2. Preprocesamiento y creación del dataset](#-2.2.-Preprocesamiento-y-creación-del-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports\n",
    "\n",
    "Una vez introducido el proyecto, se importan las librerías necesarias para el desarrollo de este apartado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 10:34:26.161255: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-22 10:34:26.212018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-22 10:34:27.079656: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "# =====================================================================\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import libraries for data preprocessing\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import src code\n",
    "from src.data import path_loader as pl\n",
    "from src.visualization import visualize\n",
    "from src.data import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config file\n",
    "# =====================================================================\n",
    "SETTINGS_PATH = \"../config.ini\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read(SETTINGS_PATH)\n",
    "\n",
    "config_paths = config[\"paths\"]\n",
    "data_path = config_paths[\"data_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos\n",
    "\n",
    "Cargamos los datos a preprocesar que se usarán para crear el dataset para el modelo de difusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv data\n",
    "# =====================================================================\n",
    "path = f\"{data_path}/processed/pokedex_cleaned.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Show the df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json data paths\n",
    "# =====================================================================\n",
    "image_paths = pl.get_image_paths(f\"{data_path}/interim/image_paths.json\")\n",
    "\n",
    "# plot random images\n",
    "visualize.plot_image_paths(image_paths, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una vez cargados los datos seleccionados para el entrenamiento del modelo que se realizó en el anterior notebook, se procede a su preprocesado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento y creación del dataset\n",
    "\n",
    "Se puede observar que los sprites de Pokémon necesitan un preprocesamiento que permita eliminar el fondo de los spries y así centrar la atención del modelo en el Pokémon en sí. Por ello, en la parte de preprocesado de los datos, se realizará un recorte del fondo de las imágenes. Con esto, se eliminará el ruido y se centrará la atención del modelo en el Pokémon en sí. Por otro lado, se necesita procesar las etiquetas para poder ser usadas en el modelo de difusión. Para ello, se codificarán las etiquetas en un formato one-hot encoding.\n",
    "\n",
    "En este punto tenemos toda la información necesaria para poder crear el dataset de entrenamiento del modelo de difusión. Pues, por un lado tenemos la información de los Pokémon y por otro lado, tenemos las imágenes de los Pokémon (aunque estas últimas sean en path para ahorar tiempo de ejecución en este preprocesado).\n",
    "    \n",
    "Por tanto el preprocesado de las imágenes y etiquetas y la creación del dataset se realizará en los siguientes pasos:\n",
    "\n",
    "- **Asignación de tipos a los Pokémon:** Es decir, asociar cada imagen con el tipo de Pokémon que representa. Esto permitirá tener ya un dataset, aunque este no esté preprocesado. Con esto se permite hacer cualquier otro tipo de procesamiento. En este dataset se guardará el path de la imagen y el tipo del Pokémon.\n",
    "\n",
    "- **Preprocesado de datos:** Recorte del fondo de las imágenes para eliminar el ruido y centrar la atención del modelo en el Pokémon en sí y procesado de las etiquetas para poder ser usadas en el modelo de difusión, es decir, codificación de las etiquetas. Este proceso se realizará conjunto con la creación del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Asignación de tipos a los Pokémon\n",
    "\n",
    "Para ello, usaremos la función `dataset_dict()` que dado el dataframe con los datos de los Pokémon y la lista de paths de los sprites, devuelve un diccionario con los datos ya asociados `{path: tipo}`. Posteriormente, se guardará este diccionario en un archivo `.json` para su posterior uso.\n",
    "\n",
    "A la hora de hacer el preprocesamiento y crear el dataset, podremos usar directamente este diccionario o podemos prescindir de él y hacer el preprocesamiento directamente con el dataframe y la lista de paths de los sprites. Aunque interemediamente, la función que hace el preprocesamiento y creación del dataset, usará esta función si no se le pasa como argumento para hacer el preprocesamiento. Pero, como se ha explicado antes, se hace explicitamente este paso para poder a partir de este punto, hacer cualquier otro tipo de procesamiento y creación de dataset y para dividir el preprocesamiento en dos partes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the image paths as keys and the pokemon type as values\n",
    "# =====================================================================\n",
    "data_dict = create_dataset.dataset_dict(\n",
    "    image_paths,\n",
    "    df,\n",
    "    save=True,\n",
    "    save_path=f\"{data_path}/interim/pokemon_dict_dataset.json\",\n",
    ")\n",
    "\n",
    "# Check the data dictionary\n",
    "# =====================================================================\n",
    "print(\n",
    "    f\"- Number of images: {len(data_dict)} \\n\"\n",
    "    f\"- Example data: {random.choice(list(data_dict.items()))} \\n\"\n",
    "    f\"- Example data visualization: \"\n",
    ")\n",
    "\n",
    "# plot random images with same type\n",
    "visualize.plot_image_paths(data_dict, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Preprocesamiento y creación del dataset\n",
    "\n",
    "En el proceso de preprocesamiento de datos, implementamos cuatro etapas clave para preparar de manera eficiente y efectiva los datos para el entrenamiento del modelo generativo, estas etapas se llevan a cabo en la función de `dataset_tf()`:\n",
    "\n",
    "- **Binarización de Etiquetas de Tipos de Pokémon**: Las etiquetas de los tipos de Pokémon se convierten en vectores binarios de 18 elementos. Cada elemento del vector representa un tipo de Pokémon. Esta conversión es crucial pues el modelo debe de procesar etiquetas nuúmericas no en formato texto.\n",
    "\n",
    "- **Recorte de Imágenes**: Las imágenes se recortan para eliminar el fondo y centrar los sprites de los Pokémon. Esto se realiza para reducir el ruido y enfocar la atención del modelo en el Pokémon en sí. El proceso implica identificar el contorno del Pokémon (basándose en la diferencia de color con el fondo blanco) y recortar la imagen en función de este contorno.\n",
    "\n",
    "- **Conversión y Escalado de Imágenes**: Las imágenes se convierten a tensores con `3 canales (RGB)` y se redimensionan a un tamaño uniforme de `(64x64x3)` píxeles. Esta uniformidad es esencial para garantizar un procesamiento consistente y eficiente durante el entrenamiento, y el tamaño elegido representa un equilibrio entre preservar detalles importantes y limitar la carga computacional.\n",
    "\n",
    "- **Normalización de Píxeles**: Los valores de píxeles de las imágenes se normalizan desde el rango original `[0,255]` a `[-1,1]`. Esta normalización facilita un entrenamiento más estable y efectivo del modelo de difusión, pues los datos adecuadamente centrados y escalados pueden mejorar significativamente la eficiencia del aprendizaje.\n",
    "\n",
    "Adicionalmente, los datos se estructuran en un formato `tf.data.Dataset`, que aplica el preprocesamiento descrito a través de las funciones `img_preprocess()` y `label_preprocess()`. La estructura del `tf.data.Dataset` se optimiza con técnicas como barajado (`shuffle`), memorización en caché (`cache`), agrupamiento en lotes (`batch`) y anticipación (`prefetch`), mejorando así la eficiencia del entrenamiento al gestionar de manera más efectiva la carga y preparación de los datos.\n",
    "\n",
    "<span style=\"color: red; font-size: 1.5em;\">&#9888;</span> <i><small>**NOTA:** La normalización de las imágenes en el rango `[-1,1]` se prefiere sobre `[0,1]` por varias razones:\n",
    "\n",
    "- **Centrado de Datos**: Normalizar a `[-1, 1]` centra los datos alrededor de cero, lo que puede mejorar la eficiencia del entrenamiento. Los pesos de la red aprenden más eficientemente con datos de entrada centrados.\n",
    "\n",
    "- **Mejor Distribución de los Gradientes**: Con los datos centrados, la distribución de los gradientes durante el entrenamiento tiende a ser más estable, lo cual es vital para un modelo generativo como el de difusión.\n",
    "\n",
    "- **Prevención de Saturación en la Activación**: En algunos casos, especialmente con funciones de activación que saturan, tener datos de entrada en un rango más amplio puede prevenir la saturación de la función de activación en las primeras etapas del entrenamiento, evitando así el entrenamiento lento o estancado.\n",
    "\n",
    "</small></i>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# =====================================================================\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create the tf dataset\n",
    "# =====================================================================\n",
    "dataset_tf = create_dataset.dataset_tf(\n",
    "    image_paths=image_paths, df=df, img_size=IMG_SIZE, batch_size=BATCH_SIZE\n",
    ")  # remember that you can also give the data_dict as input instead of the image_paths and df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n",
    "# =====================================================================\n",
    "for img, label in dataset_tf.take(1):\n",
    "    print(\n",
    "        f\"- The shape of the dataset data is: {img.shape} => batch_size: {img.shape[0]}, height: {img.shape[1]}, width: {img.shape[2]}, channels: {img.shape[3]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"- The shape of the dataset labels is: {label.shape} => batch_size: {label.shape[0]}, number of labels: {label.shape[1]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# =====================================================================\n",
    "visualize.plot_images_batch(dataset_tf, df, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una vez preparado el dataset, podemos empezar a crear el modelo de difusión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BACK TO TOP](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
