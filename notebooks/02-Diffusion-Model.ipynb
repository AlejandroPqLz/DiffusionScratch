{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pokémon Diffusion<a id=\"top\"></a>**\n",
    "\n",
    "> #### ``02-Diffusion-Model.ipynb``\n",
    "\n",
    "<i><small>**Alumno:** Alejandro Pequeño Lizcano<br>Última actualización: 18/03/2024</small></i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: introducir el mdoelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports\n",
    "\n",
    "Una vez introducido el proyecto, se importan las librerías necesarias para el desarrollo de este apartado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# =====================================================================\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import libraries for data preprocessing\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import src code\n",
    "from src.data import path_loader as pl\n",
    "from src.data import create_dataset\n",
    "from src.visualization import visualize\n",
    "from src.models import forward_diffusion as fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config file\n",
    "# =====================================================================\n",
    "SETTINGS_PATH = \"../config.ini\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read(SETTINGS_PATH)\n",
    "\n",
    "config_paths = config[\"paths\"]\n",
    "data_path = config_paths[\"data_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Difusión\n",
    "\n",
    "TODO: Introducir mejor\n",
    "\n",
    "El modelo usado para la predicción del ruido. Según muchos papers, se podría usar cualquier red neuronal, ya que no existe una arquitectura específica y depende del conjunto de datos con el que se entrene, no obstante, la más usada para la síntesis de imágenes y la que se ha usado en este proyecto es la arquitectura **U-Net** por sus características de recuperación de la información manteniendo la dimensionalidad de la imagen.\n",
    "\n",
    "Esta arquitectura se caracteriza por tener una parte de codificación y una parte de decodificación. La parte de codificación se encarga de reducir la dimensionalidad de la imagen de entrada y la parte de decodificación se encarga de reconstruir la imagen original a partir de la imagen codificada.\n",
    "\n",
    "Podemos encontrar dos funciones, por una parte, ``block()``, que se encarga de definir el bloque de difusión y, por otra parte, ``build_ddpm_model()``, que se encarga de definir la arquitectura **U-Net**.\n",
    "\n",
    "- ``block()``: El bloque de difusión contiene tres parámetros:\n",
    "\n",
    "    - ``x_parameter``: es el tensor de entrada que contiene la imagen original o la imagen con ruido en cada paso de difusión.\n",
    "    - ``time_parameter`` es el tensor que indica el paso de difusión en el que nos encontramos. Se usa para calcular el valor de **$\\beta$** según el *scheduler* que hayamos elegido.\n",
    "\n",
    "    Dentro del bloque de difusión, se aplican transformaciones a cada uno de estos parámetros, lo que puede incluir capas densas, normalización y activación ReLU. Estas transformaciones capturan las relaciones y dependencias entre los diferentes aspectos de la entrada (imagen y tiempo). Finalmente, se calcula la imagen nueva con el ruido añadido.\n",
    "\n",
    "-  El proceso de difusión utiliza una arquitectura de tipo **U-Net** modificada con bloques ``block`` que toman en cuenta la imagen (``x_parameter``) y el tensor tiempo (``time_parameter``). Posteriormente, se realizan operaciones de convolución y pooling para reducir la resolución de la imagen mientras se procesa la información temporal. Luego, se realiza un proceso de decodificación utilizando operaciones de upsampling y concatenación para generar una imagen de salida que tiene la misma resolución que la imagen de entrada. Después de este proceso, se añade una capa **MLP** para procesar la información temporal y generar una imagen de salida. Finalmente, se devuelve la imagen de salida.\n",
    "\n",
    "\n",
    "---\n",
    "<i><small>**Más infromación** sobre el porqué matemático de la función de pérdida, aunque ya explicado, se puede encontrar en el paper [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) y una explicación más clara en la página [Diffusion Model Clearly Explained!](https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166).\n",
    "\n",
    "<span style=\"color: red; font-size: 1.5em;\">&#9888;</span> **NOTA:** El proceso matemático para llegar a esta fórmula es muy complejo para explicarlo en este notebook. Sin embargo, en el futuro informe se explicará con más detalle. \n",
    "</small></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(x_img: tf.Tensor, x_ts: tf.Tensor, x_label: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"The block of the diffusion model\n",
    "\n",
    "    :param x_img: The image to process\n",
    "    :param x_ts: The time steps to process\n",
    "    :param x_label: The label to process\n",
    "    :return: The processed image\n",
    "    \"\"\"\n",
    "\n",
    "    x_parameter = layers.Conv2D(128, kernel_size=3, padding=\"same\")(x_img)\n",
    "    x_parameter = layers.Activation(\"relu\")(x_parameter)\n",
    "\n",
    "    time_parameter = layers.Dense(128)(x_ts)\n",
    "    time_parameter = layers.Activation(\"relu\")(time_parameter)\n",
    "    time_parameter = layers.Reshape((1, 1, 128))(time_parameter)\n",
    "\n",
    "    label_parameter = layers.Dense(128)(x_label)\n",
    "    label_parameter = layers.Activation(\"relu\")(label_parameter)\n",
    "    label_parameter = layers.Reshape((1, 1, 128))(label_parameter)\n",
    "\n",
    "    x_parameter = x_parameter * label_parameter + time_parameter\n",
    "\n",
    "    # -----\n",
    "    x_out = layers.Conv2D(128, kernel_size=3, padding=\"same\")(x_img)\n",
    "    x_out = x_out + x_parameter\n",
    "    x_out = layers.LayerNormalization()(x_out)\n",
    "    x_out = layers.Activation(\"relu\")(x_out)\n",
    "\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. El proceso de difusión utiliza una arquitectura de tipo **U-Net** modificada con bloques ``block`` que toman en cuenta la imagen (``x_parameter``), el tensor tiempo (``time_parameter``) y la etiqueta (``label_parameter``). Posteriormente, se realizan operaciones de convolución y pooling para reducir la resolución de la imagen mientras se procesa la información temporal y de etiqueta. Luego, se realiza un proceso de decodificación utilizando operaciones de upsampling y concatenación para generar una imagen de salida que tiene la misma resolución que la imagen de entrada. Después de este proceso, se añade una capa **MLP** para procesar la información temporal y de etiqueta y generar una imagen de salida. Finalmente, se devuelve la imagen de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ddpm_model() -> tf.keras.models.Model:\n",
    "    \"\"\"Creates the diffusion model\n",
    "\n",
    "    :return: The diffusion model\n",
    "    \"\"\"\n",
    "\n",
    "    x = x_input = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"x_input\")\n",
    "\n",
    "    x_ts = x_ts_input = layers.Input(shape=(1,), name=\"x_ts_input\")\n",
    "    x_ts = layers.Dense(192)(x_ts)\n",
    "    x_ts = layers.LayerNormalization()(x_ts)\n",
    "    x_ts = layers.Activation(\"relu\")(x_ts)\n",
    "\n",
    "    x_label = x_label_input = layers.Input(shape=(NUM_CLASSES), name=\"x_label_input\")\n",
    "    x_label = layers.Dense(192)(x_label)\n",
    "    x_label = layers.LayerNormalization()(x_label)\n",
    "    x_label = layers.Activation(\"relu\")(x_label)\n",
    "\n",
    "    # ----- left ( down ) -----\n",
    "    x = x64 = block(x, x_ts, x_label)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "    x = x32 = block(x, x_ts, x_label)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "    x = x16 = block(x, x_ts, x_label)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "    x = x8 = block(x, x_ts, x_label)\n",
    "\n",
    "    # ----- MLP -----\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Concatenate()([x, x_ts, x_label])\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Dense(8 * 8 * 32)(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Reshape((8, 8, 32))(x)\n",
    "\n",
    "    # ----- right ( up ) -----\n",
    "    x = layers.Concatenate()([x, x8])\n",
    "    x = block(x, x_ts, x_label)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, x16])\n",
    "    x = block(x, x_ts, x_label)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, x32])\n",
    "    x = block(x, x_ts, x_label)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, x64])\n",
    "    x = block(x, x_ts, x_label)\n",
    "\n",
    "    # ----- output -----\n",
    "    x = layers.Conv2D(3, kernel_size=1, padding=\"same\")(x)\n",
    "    model = tf.keras.models.Model([x_input, x_ts_input, x_label_input], x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "# =====================================================================\n",
    "model = build_ddpm_model()\n",
    "\n",
    "# Compile the model\n",
    "# =====================================================================\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "model.compile(loss=loss_fn, optimizer=optimizer)\n",
    "\n",
    "# Show the model summary\n",
    "# =====================================================================\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
