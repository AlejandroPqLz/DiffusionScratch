{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pokémon Diffusion<a id=\"top\"></a>**\n",
    "\n",
    "> #### ``02-Diffusion-Model.ipynb``\n",
    "\n",
    "<i><small>**Alumno:** Alejandro Pequeño Lizcano<br>Última actualización: 18/03/2024</small></i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: introducir el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports\n",
    "\n",
    "Una vez introducido el proyecto, se importan las librerías necesarias para el desarrollo de este apartado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 22:03:11.361995: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-22 22:03:11.393988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-22 22:03:11.906987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "# =====================================================================\n",
    "\n",
    "# Import libraries for data preprocessing\n",
    "import configparser\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Import src code\n",
    "from src.data import path_loader as pl\n",
    "from src.data import create_dataset\n",
    "from src.visualization import visualize\n",
    "from src.model.diffusion import DiffusionModel\n",
    "from src.utils.utils import PROJECT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# =====================================================================\n",
    "config = configparser.ConfigParser()\n",
    "config.read(PROJECT_DIR / \"config.ini\")\n",
    "config_hp = config[\"hyperparameters\"]\n",
    "\n",
    "IMG_SIZE = int(config_hp[\"img_size\"])\n",
    "NUM_CLASSES = int(config_hp[\"num_classes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Difusión\n",
    "\n",
    "TODO: Introducir mejor\n",
    "\n",
    "El modelo usado para la predicción del ruido. Según muchos papers, se podría usar cualquier red neuronal, ya que no existe una arquitectura específica y depende del conjunto de datos con el que se entrene, no obstante, la más usada para la síntesis de imágenes y la que se ha usado en este proyecto es la arquitectura **U-Net** por sus características de recuperación de la información manteniendo la dimensionalidad de la imagen.\n",
    "\n",
    "Esta arquitectura se caracteriza por tener una parte de codificación y una parte de decodificación. La parte de codificación se encarga de reducir la dimensionalidad de la imagen de entrada y la parte de decodificación se encarga de reconstruir la imagen original a partir de la imagen codificada.\n",
    "\n",
    "Podemos encontrar dos funciones, por una parte, ``block()``, que se encarga de definir el bloque de difusión y, por otra parte, ``build_ddpm_model()``, que se encarga de definir la arquitectura **U-Net**.\n",
    "\n",
    "- ``block()``: El bloque de difusión contiene tres parámetros:\n",
    "\n",
    "    - ``x_parameter``: es el tensor de entrada que contiene la imagen original o la imagen con ruido en cada paso de difusión.\n",
    "    - ``time_parameter`` es el tensor que indica el paso de difusión en el que nos encontramos. Se usa para calcular el valor de **$\\beta$** según el *scheduler* que hayamos elegido.\n",
    "\n",
    "    Dentro del bloque de difusión, se aplican transformaciones a cada uno de estos parámetros, lo que puede incluir capas densas, normalización y activación ReLU. Estas transformaciones capturan las relaciones y dependencias entre los diferentes aspectos de la entrada (imagen y tiempo). Finalmente, se calcula la imagen nueva con el ruido añadido.\n",
    "\n",
    "-  El proceso de difusión utiliza una arquitectura de tipo **U-Net** modificada con bloques ``block`` que toman en cuenta la imagen (``x_parameter``) y el tensor tiempo (``time_parameter``). Posteriormente, se realizan operaciones de convolución y pooling para reducir la resolución de la imagen mientras se procesa la información temporal. Luego, se realiza un proceso de decodificación utilizando operaciones de upsampling y concatenación para generar una imagen de salida que tiene la misma resolución que la imagen de entrada. Después de este proceso, se añade una capa **MLP** para procesar la información temporal y generar una imagen de salida. Finalmente, se devuelve la imagen de salida.\n",
    "\n",
    "\n",
    "---\n",
    "<i><small>**Más infromación** sobre el porqué matemático de la función de pérdida, aunque ya explicado, se puede encontrar en el paper [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) y una explicación más clara en la página [Diffusion Model Clearly Explained!](https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166).\n",
    "\n",
    "<span style=\"color: red; font-size: 1.5em;\">&#9888;</span> **NOTA:** El proceso matemático para llegar a esta fórmula es muy complejo para explicarlo en este notebook. Sin embargo, en el futuro informe se explicará con más detalle. \n",
    "</small></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard callback for monitoring training progress\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./logs\", histogram_freq=1\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model = build_ddpm_model()\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(x_img: tf.Tensor, x_ts: tf.Tensor, x_label: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"The block of the diffusion model\n",
    "\n",
    "    :param x_img: The image to process\n",
    "    :param x_ts: The time steps to process\n",
    "    :param x_label: The label to process\n",
    "    :return: The processed image\n",
    "    \"\"\"\n",
    "\n",
    "    x_parameter = layers.Conv2D(128, kernel_size=3, padding=\"same\")(x_img)\n",
    "    x_parameter = layers.Activation(\"relu\")(x_parameter)\n",
    "\n",
    "    time_parameter = layers.Dense(128)(x_ts)\n",
    "    time_parameter = layers.Activation(\"relu\")(time_parameter)\n",
    "    time_parameter = layers.Reshape((1, 1, 128))(time_parameter)\n",
    "\n",
    "    label_parameter = layers.Dense(128)(x_label)\n",
    "    label_parameter = layers.Activation(\"relu\")(label_parameter)\n",
    "    label_parameter = layers.Reshape((1, 1, 128))(label_parameter)\n",
    "\n",
    "    x_parameter = x_parameter * label_parameter + time_parameter\n",
    "\n",
    "    # -----\n",
    "    x_out = layers.Conv2D(128, kernel_size=3, padding=\"same\")(x_img)\n",
    "    x_out = x_out + x_parameter\n",
    "    x_out = layers.LayerNormalization()(x_out)\n",
    "    x_out = layers.Activation(\"relu\")(x_out)\n",
    "\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. El proceso de difusión utiliza una arquitectura de tipo **U-Net** modificada con bloques ``block`` que toman en cuenta la imagen (``x_parameter``), el tensor tiempo (``time_parameter``) y la etiqueta (``label_parameter``). Posteriormente, se realizan operaciones de convolución y pooling para reducir la resolución de la imagen mientras se procesa la información temporal y de etiqueta. Luego, se realiza un proceso de decodificación utilizando operaciones de upsampling y concatenación para generar una imagen de salida que tiene la misma resolución que la imagen de entrada. Después de este proceso, se añade una capa **MLP** para procesar la información temporal y de etiqueta y generar una imagen de salida. Finalmente, se devuelve la imagen de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ddpm_model() -> tf.keras.models.Model:\n",
    "    \"\"\"Creates the diffusion model\n",
    "\n",
    "    :return: The diffusion model\n",
    "    \"\"\"\n",
    "\n",
    "    x = x_input = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"x_input\")\n",
    "\n",
    "    x_ts = x_ts_input = layers.Input(shape=(1,), name=\"x_ts_input\")\n",
    "    x_ts = layers.Dense(192)(x_ts)\n",
    "    x_ts = layers.LayerNormalization()(x_ts)\n",
    "    x_ts = layers.Activation(\"relu\")(x_ts)\n",
    "\n",
    "    x_label = x_label_input = layers.Input(shape=(NUM_CLASSES,), name=\"x_label_input\")\n",
    "    x_label = layers.Dense(192)(x_label)\n",
    "    x_label = layers.LayerNormalization()(x_label)\n",
    "    x_label = layers.Activation(\"relu\")(x_label)\n",
    "\n",
    "    # ----- left ( down ) -----\n",
    "    x = x64 = block(x, x_ts, x_label)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "    x = x32 = block(x, x_ts, x_label)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "    x = x16 = block(x, x_ts, x_label)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "    x = x8 = block(x, x_ts, x_label)\n",
    "\n",
    "    # ----- MLP -----\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Concatenate()([x, x_ts, x_label])\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Dense(8 * 8 * 32)(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Reshape((8, 8, 32))(x)\n",
    "\n",
    "    # ----- right ( up ) -----\n",
    "    x = layers.Concatenate()([x, x8])\n",
    "    x = block(x, x_ts, x_label)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, x16])\n",
    "    x = block(x, x_ts, x_label)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, x32])\n",
    "    x = block(x, x_ts, x_label)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, x64])\n",
    "    x = block(x, x_ts, x_label)\n",
    "\n",
    "    # ----- output -----\n",
    "    x = layers.Conv2D(3, kernel_size=1, padding=\"same\")(x)\n",
    "    model = tf.keras.models.Model([x_input, x_ts_input, x_label_input], x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "# =====================================================================\n",
    "model = build_ddpm_model()\n",
    "\n",
    "# Compile the model\n",
    "# =====================================================================\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "model.compile(loss=loss_fn, optimizer=optimizer)\n",
    "\n",
    "# Show the model summary\n",
    "# =====================================================================\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BACK TO TOP](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
